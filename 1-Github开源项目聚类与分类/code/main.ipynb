{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b14c8b9e-c634-401e-8035-21ee29c0bbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odps.Schema {\n",
      "  login                     string        \n",
      "  created_at                date          \n",
      "  database_id               int64         \n",
      "  location                  string        \n",
      "  company                   string        \n",
      "  bio                       string        \n",
      "  is_employee               boolean       \n",
      "  email                     string        \n",
      "  infoname                  string        \n",
      "  followers                 string        \n",
      "  following                 string        \n",
      "  time                      date          \n",
      "  name                      string        \n",
      "  lastupdatedat             date          \n",
      "  nextupdateat              date          \n",
      "}\n",
      "\n",
      "odps.Schema {\n",
      "  id                                                                          string                  \n",
      "  type                                                                        string                  \n",
      "  action                                                                      string                  \n",
      "  actor_id                                                                    int64                   \n",
      "  actor_login                                                                 string                  \n",
      "  repo_id                                                                     int64                   \n",
      "  repo_name                                                                   string                  \n",
      "  org_id                                                                      int64                   \n",
      "  org_login                                                                   string                  \n",
      "  created_at                                                                  datetime                \n",
      "  issue_id                                                                    int64                   \n",
      "  issue_number                                                                int32                   \n",
      "  issue_title                                                                 string                  \n",
      "  issue_body                                                                  string                  \n",
      "  issue_labels_name                                                           list<string>            \n",
      "  issue_labels_color                                                          list<string>            \n",
      "  issue_labels_default                                                        list<string>            \n",
      "  issue_labels_description                                                    list<string>            \n",
      "  issue_author_id                                                             int64                   \n",
      "  issue_author_login                                                          string                  \n",
      "  issue_author_type                                                           string                  \n",
      "  issue_author_association                                                    string                  \n",
      "  issue_assignee_id                                                           int64                   \n",
      "  issue_assignee_login                                                        string                  \n",
      "  issue_assignees_id                                                          list<string>            \n",
      "  issue_assignees_login                                                       list<string>            \n",
      "  issue_created_at                                                            datetime                \n",
      "  issue_updated_at                                                            datetime                \n",
      "  issue_comments                                                              int16                   \n",
      "  issue_closed_at                                                             datetime                \n",
      "  issue_comment_id                                                            int64                   \n",
      "  issue_comment_body                                                          string                  \n",
      "  issue_comment_created_at                                                    datetime                \n",
      "  issue_comment_updated_at                                                    datetime                \n",
      "  issue_comment_author_association                                            string                  \n",
      "  issue_comment_author_id                                                     int64                   \n",
      "  issue_comment_author_login                                                  string                  \n",
      "  issue_comment_author_type                                                   string                  \n",
      "  pull_commits                                                                int16                   \n",
      "  pull_additions                                                              int16                   \n",
      "  pull_deletions                                                              int16                   \n",
      "  pull_changed_files                                                          int32                   \n",
      "  pull_merged                                                                 int8                    \n",
      "  pull_merge_commit_sha                                                       string                  \n",
      "  pull_merged_at                                                              datetime                \n",
      "  pull_merged_by_id                                                           int64                   \n",
      "  pull_merged_by_login                                                        string                  \n",
      "  pull_merged_by_type                                                         string                  \n",
      "  pull_requested_reviewer_id                                                  int64                   \n",
      "  pull_requested_reviewer_login                                               string                  \n",
      "  pull_requested_reviewer_type                                                string                  \n",
      "  pull_review_comments                                                        int16                   \n",
      "  repo_description                                                            string                  \n",
      "  repo_size                                                                   int32                   \n",
      "  repo_stargazers_count                                                       int32                   \n",
      "  repo_forks_count                                                            int32                   \n",
      "  repo_language                                                               string                  \n",
      "  repo_has_issues                                                             int8                    \n",
      "  repo_has_projects                                                           int8                    \n",
      "  repo_has_downloads                                                          int8                    \n",
      "  repo_has_wiki                                                               int8                    \n",
      "  repo_has_pages                                                              int8                    \n",
      "  repo_license                                                                string                  \n",
      "  repo_default_branch                                                         string                  \n",
      "  repo_created_at                                                             datetime                \n",
      "  repo_updated_at                                                             datetime                \n",
      "  repo_pushed_at                                                              datetime                \n",
      "  pull_review_id                                                              int64                   \n",
      "  pull_review_comment_id                                                      int64                   \n",
      "  pull_review_comment_path                                                    string                  \n",
      "  pull_review_comment_position                                                string                  \n",
      "  pull_review_comment_author_id                                               int64                   \n",
      "  pull_review_comment_author_login                                            string                  \n",
      "  pull_review_comment_author_type                                             string                  \n",
      "  pull_review_comment_author_association                                      string                  \n",
      "  pull_review_comment_body                                                    string                  \n",
      "  pull_review_comment_created_at                                              datetime                \n",
      "  pull_review_comment_updated_at                                              datetime                \n",
      "  push_id                                                                     int64                   \n",
      "  push_size                                                                   int32                   \n",
      "  push_distinct_size                                                          int32                   \n",
      "  push_ref                                                                    string                  \n",
      "  push_head                                                                   string                  \n",
      "  push_before                                                                 string                  \n",
      "  push_commits_name                                                           list<string>            \n",
      "  push_commits_email                                                          list<string>            \n",
      "  push_commits_message                                                        list<string>            \n",
      "  fork_forkee_id                                                              int64                   \n",
      "  fork_forkee_full_name                                                       string                  \n",
      "  fork_forkee_owner_id                                                        int64                   \n",
      "  fork_forkee_owner_login                                                     string                  \n",
      "  fork_forkee_owner_type                                                      string                  \n",
      "  delete_ref                                                                  string                  \n",
      "  delete_ref_type                                                             string                  \n",
      "  delete_pusher_type                                                          string                  \n",
      "  create_ref                                                                  string                  \n",
      "  create_ref_type                                                             string                  \n",
      "  create_master_branch                                                        string                  \n",
      "  create_description                                                          string                  \n",
      "  create_pusher_type                                                          string                  \n",
      "  gollum_pages_page_name                                                      list<string>            \n",
      "  gollum_pages_title                                                          list<string>            \n",
      "  gollum_pages_action                                                         list<string>            \n",
      "  member_login                                                                string                  \n",
      "  member_type                                                                 string                  \n",
      "  member_id                                                                   int64                   \n",
      "  release_id                                                                  int64                   \n",
      "  release_tag_name                                                            string                  \n",
      "  release_target_commitish                                                    string                  \n",
      "  release_name                                                                string                  \n",
      "  release_draft                                                               int8                    \n",
      "  release_author_id                                                           int64                   \n",
      "  release_author_login                                                        string                  \n",
      "  release_author_type                                                         string                  \n",
      "  release_prerelease                                                          int8                    \n",
      "  release_created_at                                                          datetime                \n",
      "  release_published_at                                                        datetime                \n",
      "  release_body                                                                string                  \n",
      "  release_assets_name                                                         list<string>            \n",
      "  release_assets_uploader_login                                               list<string>            \n",
      "  release_assets_uploader_id                                                  list<string>            \n",
      "  release_assets_content_type                                                 list<string>            \n",
      "  release_assets_state                                                        list<string>            \n",
      "  release_assets_size                                                         list<string>            \n",
      "  release_assets_download_count                                               list<string>            \n",
      "  commit_comment_id                                                           int64                   \n",
      "  commit_comment_author_id                                                    int64                   \n",
      "  commit_comment_author_login                                                 string                  \n",
      "  commit_comment_author_type                                                  string                  \n",
      "  commit_comment_author_association                                           string                  \n",
      "  commit_comment_body                                                         string                  \n",
      "  commit_comment_path                                                         string                  \n",
      "  commit_comment_position                                                     string                  \n",
      "  commit_comment_line                                                         string                  \n",
      "  commit_comment_created_at                                                   datetime                \n",
      "  commit_comment_updated_at                                                   datetime                \n",
      "  pt                                                                          string                  \n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from connect import get_odps\n",
    "from get_data import get_data, delete_output\n",
    "from get_df import get_dataframe\n",
    "from read_data import read_data\n",
    "from transform import transform\n",
    "from get_dataset import get_dataset\n",
    "from context_vector import context_vec, embedding_vec\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.cluster as sc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "from cluster.KMeans import KMeans, EuclidianDistance, CosineDistance\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from MLP import MLP\n",
    "from TextCNN import TextCNN\n",
    "\n",
    "o = get_odps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f51a891-a344-448a-bd91-4860a60c8dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      0                    1                             2  \\\n",
      "0  (repo_id, 159513310)  (actor_id, 9887585)     (actor_login, snellingio)   \n",
      "1  (repo_id, 167922316)  (actor_id, 9887585)     (actor_login, snellingio)   \n",
      "2  (repo_id, 170486632)  (actor_id, 9887585)     (actor_login, snellingio)   \n",
      "3  (repo_id, 105722352)  (actor_id, 9887716)       (actor_login, vpperego)   \n",
      "4  (repo_id, 158469400)  (actor_id, 9887743)  (actor_login, ElliottMiller)   \n",
      "\n",
      "                          3                  4                 5  \n",
      "0        (type, WatchEvent)  (action, started)  (pull_merged, 0)  \n",
      "1        (type, WatchEvent)  (action, started)  (pull_merged, 0)  \n",
      "2        (type, WatchEvent)  (action, started)  (pull_merged, 0)  \n",
      "3        (type, WatchEvent)  (action, started)  (pull_merged, 0)  \n",
      "4  (type, PullRequestEvent)   (action, opened)  (pull_merged, 0)  \n"
     ]
    }
   ],
   "source": [
    "df = get_dataframe(o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "827a6528-32fe-45c1-b4b2-7007eca21ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[159513310 9887585 'snellingio' 'WatchEvent' 'started'\n",
      "  ('pull_merged', 0)]\n",
      " [167922316 9887585 'snellingio' 'WatchEvent' 'started'\n",
      "  ('pull_merged', 0)]\n",
      " [170486632 9887585 'snellingio' 'WatchEvent' 'started'\n",
      "  ('pull_merged', 0)]\n",
      " ...\n",
      " [66922941 1029811 'ToBeFree' 'WatchEvent' 'started' ('pull_merged', 0)]\n",
      " [111535895 1029811 'ToBeFree' 'WatchEvent' 'started' ('pull_merged', 0)]\n",
      " [166080712 1029811 'ToBeFree' 'ForkEvent' '' ('pull_merged', 0)]]\n",
      "     repo_id actor_id    actor_login              type   action  \\\n",
      "0  159513310  9887585     snellingio        WatchEvent  started   \n",
      "1  167922316  9887585     snellingio        WatchEvent  started   \n",
      "2  170486632  9887585     snellingio        WatchEvent  started   \n",
      "3  105722352  9887716       vpperego        WatchEvent  started   \n",
      "4  158469400  9887743  ElliottMiller  PullRequestEvent   opened   \n",
      "\n",
      "        pull_merged  \n",
      "0  (pull_merged, 0)  \n",
      "1  (pull_merged, 0)  \n",
      "2  (pull_merged, 0)  \n",
      "3  (pull_merged, 0)  \n",
      "4  (pull_merged, 0)  \n"
     ]
    }
   ],
   "source": [
    "arr = np.array(df)\n",
    "\n",
    "for i in range(100000):\n",
    "    for j in range(0,5):\n",
    "        if(len(arr[i][j])) == 2:\n",
    "            arr[i][j] = arr[i][j][1]\n",
    "print(arr)\n",
    "df = pd.DataFrame(arr)\n",
    "df.columns = ['repo_id', 'actor_id', 'actor_login', 'type', 'action', 'pull_merged']\n",
    "print(df.head())\n",
    "df.to_csv('Action.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e85a7d6-fe63-488f-aedb-b840726d1d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now loading text data...\n",
      "Now loading contribute vector data, this may take minutes.\n",
      "Text data's length:  24287\n",
      "Vector's shape:  (24287, 1638)\n",
      "Complete 0 sentences.\n",
      "Complete 1000 sentences.\n",
      "Complete 2000 sentences.\n",
      "Complete 3000 sentences.\n",
      "Complete 4000 sentences.\n",
      "Complete 5000 sentences.\n",
      "Complete 6000 sentences.\n",
      "Complete 7000 sentences.\n",
      "Complete 8000 sentences.\n",
      "Complete 9000 sentences.\n",
      "Complete 10000 sentences.\n",
      "Complete 11000 sentences.\n",
      "Complete 12000 sentences.\n",
      "Complete 13000 sentences.\n",
      "Complete 14000 sentences.\n",
      "Complete 15000 sentences.\n",
      "Complete 16000 sentences.\n",
      "Complete 17000 sentences.\n",
      "Complete 18000 sentences.\n",
      "Complete 19000 sentences.\n",
      "Complete 20000 sentences.\n",
      "Complete 21000 sentences.\n",
      "Complete 22000 sentences.\n",
      "Complete 23000 sentences.\n",
      "Complete 24000 sentences.\n"
     ]
    }
   ],
   "source": [
    "dset, repo_id = get_dataset(lambda x: np.log(1. + x))\n",
    "\n",
    "tfidf_vec, sents = transform(dset.data, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bfa4c02-51dd-4481-bf39-a3c36b695284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24287, 5000) (24287, 1638)\n",
      "(24287, 6638)\n",
      "[ 679  997 4115  421  903  446 1142 1316  649 1238  971  436  780  850\n",
      " 3169  859  647 2694  986  989]\n",
      "Std of distribution: 947.3021838357599\n"
     ]
    }
   ],
   "source": [
    "w = 1.\n",
    "print(tfidf_vec.shape, dset.vec.shape)\n",
    "features = np.concatenate((tfidf_vec, w * dset.vec), axis = 1)\n",
    "print(features.shape)\n",
    "k = 20\n",
    "HC = AgglomerativeClustering(n_clusters = k, affinity = 'cosine', linkage = 'average')\n",
    "KM = KMeans(k, CosineDistance)\n",
    "GM = GaussianMixture(n_components = k, max_iter = 1000)\n",
    "\n",
    "KM.fit(features)\n",
    "# HC.fit(features)\n",
    "# GM.fit(features)\n",
    "y = KM.labels\n",
    "# y = GM.labels_\n",
    "# y = HC.lables_\n",
    "distribution = np.sum(np.ones((k, 1)) @ y.reshape(1, -1) == np.arange(k).reshape(k, 1) @ np.ones((1, y.shape[0])), axis = 1)\n",
    "print(distribution)\n",
    "print('Std of distribution: {std}'.format(std = np.std(distribution)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8bc0dd0-28a4-46c0-8d59-8cdb5cb2e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_vec = embedding_vec(sents[0: 10000], 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13661488-f9f8-4421-bd17-5f1e096dd2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27363862575529285"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette_score(features,KM.labels,metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b8d3736-60ba-43d0-a350-ddf9f815e70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "class datasets():\n",
    "    def __init__(self, X, y):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim, dropout = 0.5):\n",
    "        # assert len(hidden_dims) == 3\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.w1 = nn.Linear(input_dim, hidden_dims[0])\n",
    "        self.w2 = nn.Linear(hidden_dims[0], hidden_dims[1])\n",
    "        self.w3 = nn.Linear(hidden_dims[1], hidden_dims[2])\n",
    "        self.w4 = nn.Linear(hidden_dims[2], output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        nn.init.kaiming_normal_(self.w1.weight)\n",
    "        nn.init.kaiming_normal_(self.w2.weight)\n",
    "        nn.init.kaiming_normal_(self.w3.weight)\n",
    "        nn.init.kaiming_normal_(self.w4.weight)\n",
    "        \n",
    "    def forward(self, X):\n",
    "\n",
    "        l1 = self.relu(self.dropout(self.w1(X)))\n",
    "        l2 = self.relu(self.dropout(self.w2(l1)))\n",
    "        l3 = self.relu(self.dropout(self.w3(l2)))\n",
    "        out = self.w4(l3)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class tcnn(nn.Module):\n",
    "    def __init__(self, seq_len, vocab_size, output_dim, dropout = 0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, 128)\n",
    "        self.linear1 = nn.Linear(vocab_size, 128)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 128, (2, 128)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((seq_len - 1, 1))\n",
    "        )\n",
    "        self.rnn = nn.LSTM(128, 256, 2, batch_first = True, bidirectional = True)\n",
    "        self.linear2 = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, output_dim)\n",
    "        ) \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        nn.init.kaiming_normal_(self.embedding.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        if len(x.shape) < 3:\n",
    "            x = self.embedding(x)\n",
    "        # 64, 102, 10000\n",
    "        else:\n",
    "            x = self.linear1(x) \n",
    "        # 64, 102, 128\n",
    "        # x = x.unsqueeze(1) # 64, 1, 102, 128\n",
    "        # x = self.conv(x) # 64, 128, 2, 1\n",
    "        x = self.rnn(x)[0][:, -1, :]\n",
    "        # x = x.view(x.size(0), -1) # 64, 128\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x) # 64, 20\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "443e64e2-3187-4f43-a605-28f4edc9ff50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.99938\n",
      "Got 2568 / 19428 correct (13.22) on validation dataset\n",
      "Iteration 100, loss = 1.91899\n",
      "Got 10232 / 19428 correct (52.67) on validation dataset\n",
      "Iteration 200, loss = 0.62401\n",
      "Got 18144 / 19428 correct (93.39) on validation dataset\n",
      "Iteration 300, loss = 0.23786\n",
      "Got 19032 / 19428 correct (97.96) on validation dataset\n",
      "Iteration 0, loss = 0.31813\n",
      "Got 19056 / 19428 correct (98.09) on validation dataset\n",
      "Iteration 100, loss = 0.05084\n",
      "Got 19156 / 19428 correct (98.60) on validation dataset\n",
      "Iteration 200, loss = 0.12111\n",
      "Got 19205 / 19428 correct (98.85) on validation dataset\n",
      "Iteration 300, loss = 0.05347\n",
      "Got 19336 / 19428 correct (99.53) on validation dataset\n",
      "Iteration 0, loss = 0.05342\n",
      "Got 19344 / 19428 correct (99.57) on validation dataset\n",
      "Iteration 100, loss = 0.09797\n",
      "Got 19362 / 19428 correct (99.66) on validation dataset\n",
      "Iteration 200, loss = 0.07282\n",
      "Got 19370 / 19428 correct (99.70) on validation dataset\n",
      "Iteration 300, loss = 0.04832\n",
      "Got 19401 / 19428 correct (99.86) on validation dataset\n",
      "Iteration 0, loss = 0.02038\n",
      "Got 19387 / 19428 correct (99.79) on validation dataset\n",
      "Iteration 100, loss = 0.04640\n",
      "Got 19410 / 19428 correct (99.91) on validation dataset\n",
      "Iteration 200, loss = 0.03019\n",
      "Got 19404 / 19428 correct (99.88) on validation dataset\n",
      "Iteration 300, loss = 0.02920\n",
      "Got 19419 / 19428 correct (99.95) on validation dataset\n",
      "Iteration 0, loss = 0.04089\n",
      "Got 19418 / 19428 correct (99.95) on validation dataset\n",
      "Iteration 100, loss = 0.03805\n",
      "Got 19421 / 19428 correct (99.96) on validation dataset\n",
      "Iteration 200, loss = 0.00476\n",
      "Got 19422 / 19428 correct (99.97) on validation dataset\n",
      "Iteration 300, loss = 0.01400\n",
      "Got 19427 / 19428 correct (99.99) on validation dataset\n",
      "\n",
      "\n",
      "Result on test dataset:\n",
      "Got 4781 / 4857 correct (98.44) on validation dataset\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.tensor(features[0:24285], dtype = torch.float32)\n",
    "y_train = torch.tensor(y[0:24285], dtype = torch.long)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.1765)\n",
    "\n",
    "num_folds = 5\n",
    "NUM_TRAIN = 24285\n",
    "num_train = NUM_TRAIN - NUM_TRAIN // num_folds\n",
    "num_val = NUM_TRAIN - num_train\n",
    "\n",
    "#loader_test = DataLoader(datasets(X_test, y_test), batch_size=64,\n",
    "#                            sampler=sampler.SubsetRandomSampler(range(num_test)))\n",
    "\n",
    "# print(y_train.shape)\n",
    "\n",
    "X_train_folds = np.split(X_train, num_folds, axis = 0)\n",
    "y_train_folds = np.split(y_train, num_folds, axis = 0)\n",
    "\n",
    "input_dim = 6638\n",
    "hidden_dims = [1024, 1024, 1024]\n",
    "output_dim = 20\n",
    "\n",
    "\n",
    "# 超参\n",
    "lr = 2e-4 # 1e-2 for sgd\n",
    "betas = (0.9, 0.999) # beta0 = 0.5，0.75, 0.99\n",
    "\n",
    "# 最优模型\n",
    "best_model = None\n",
    "best_acc = 0\n",
    "\n",
    "k = 0\n",
    "X_train_fold = np.concatenate([ fold for j, fold in enumerate(X_train_folds) if k != j ])\n",
    "y_train_fold = np.concatenate([ fold for j, fold in enumerate(y_train_folds) if k != j ])\n",
    "\n",
    "loader_train = DataLoader(datasets(X_train_fold, y_train_fold), batch_size=64,\n",
    "                      sampler=sampler.SubsetRandomSampler(range(num_train)))\n",
    "loader_test = DataLoader(datasets(X_train_folds[k], y_train_folds[k]), batch_size=64,\n",
    "                        sampler=sampler.SubsetRandomSampler(range(num_val)))\n",
    "\n",
    "model = Model(input_dim, hidden_dims, output_dim, 0.5).cuda()\n",
    "# model = tcnn(102, 10000, 20).cuda()\n",
    "\n",
    "# 优化器\n",
    "sgd = optim.SGD(model.parameters(), lr = lr, momentum = 0.9, weight_decay = 1e-5)\n",
    "adam = optim.Adam(model.parameters(), lr = lr, betas = betas, weight_decay = 0.)\n",
    "\n",
    "acc = train(model, adam, loader_train, epochs = 5)\n",
    "\n",
    "\n",
    "print(\"\\n\\nResult on test dataset:\")\n",
    "check_accuracy(loader_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "275006fc-feb1-417e-92d3-48147a900339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18 12 10  0 16  0  5 14 10 16 16  2  0  8 13  6 10  0 11  5]\n"
     ]
    }
   ],
   "source": [
    "# _, test_pred = model(X_train_folds[0]).max(1)\n",
    "print(y[0: 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91b450f8-8ba5-4ce7-9700-d903114f1f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loader_train, loader_val = None, epochs = 1):\n",
    "    acc = 0.\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if t % 100 == 0:\n",
    "                print('Iteration %d, loss = %.5f' % (t, loss.item()))\n",
    "                if loader_val == None:\n",
    "                    check_accuracy(loader_train, model)\n",
    "                else:\n",
    "                    acc = check_accuracy(loader_test, model, need_acc = True)\n",
    "    if acc > 0:\n",
    "        return acc\n",
    "def check_accuracy(loader_val, model, loader_train = None, need_acc = False):\n",
    "      \n",
    "    num_correct_val = 0\n",
    "    num_samples_val = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader_val:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct_val += (preds == y).sum()\n",
    "            num_samples_val += preds.size(0)\n",
    "        \n",
    "        val_acc = float(num_correct_val) / num_samples_val\n",
    "        print('Got %d / %d correct (%.2f) on validation dataset' % (num_correct_val, num_samples_val, 100 * val_acc))\n",
    "        \n",
    "    if need_acc:\n",
    "        return 100 * val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2a067cb-a619-4026-b369-5639dc2796dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x230b418aee0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import jieba\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "text3 = \" \".join(np.array(fixed_data)[y == 3])\n",
    "\n",
    "text7 = \" \".join(np.array(fixed_data)[y == 7])\n",
    "\n",
    "text9 = \" \".join(np.array(fixed_data)[y == 9])\n",
    "\n",
    "wc = WordCloud(\n",
    "\n",
    "# 设置字体，不指定就会出现乱码\n",
    "\n",
    "# 设置背景色\n",
    "\n",
    "background_color='white',\n",
    "\n",
    "# 设置背景宽\n",
    "\n",
    "width=500,\n",
    "\n",
    "# 设置背景高\n",
    "\n",
    "height=350,\n",
    "\n",
    "# 最大字体\n",
    "\n",
    "max_font_size=50,\n",
    "\n",
    "# 最小字体\n",
    "\n",
    "min_font_size=10,\n",
    "\n",
    "mode='RGBA'\n",
    "\n",
    "#colormap='pink'\n",
    "\n",
    ")\n",
    "\n",
    "wc.generate(text9)\n",
    "wc.to_file(r\"wordcloud9.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a15e5b2a-693e-4ae2-b95f-55e08f2cfc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A [True, True, False, True, True]\n",
      "\n",
      "sh [True, True, True, True, True]\n",
      "\n",
      "iter [True, True, True, True, True]\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaa [True, True, False, True, True]\n",
      "\n",
      "adis [True, True, True, True, True]\n",
      "\n",
      "distan [True, True, True, True, True]\n",
      "\n",
      "is [True, True, True, True, False]\n",
      "\n",
      "sh iter adis distan\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from transform import word_filter\n",
    "d = 'asd555asd'\n",
    "d = re.sub(r'[^a-zA-Z]', ' ', d)\n",
    "s = 'A sh iter  aaaaaaaaaaaaaaaaaaaaaa adis distan is'\n",
    "print(word_filter(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "174a26e3-0a55-4faf-8b94-befc75d6688c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 388860  611562 1117948]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(repo_id)[[2,8,16]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69d86eea-8df7-4f96-9a6e-fd6d62f10877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odps.Record {\n",
      "  repo_name         'VsVim/VsVim'\n",
      "}\n",
      "odps.Record {\n",
      "  repo_name         'holman/dotfiles'\n",
      "}\n",
      "odps.Record {\n",
      "  repo_name         'jaredpar/VsVim'\n",
      "}\n",
      "odps.Record {\n",
      "  repo_name         'kwgoodman/bottleneck'\n",
      "}\n",
      "odps.Record {\n",
      "  repo_name         'pydata/bottleneck'\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "ids = (388860, 611562, 1117948)\n",
    "sql = \"\"\"\n",
    "select distinct(repo_name) from ods_github_log\n",
    "where pt > 20190101 and pt < 20200101\n",
    "and repo_id in {list}\n",
    "\"\"\".format(list = ids)\n",
    "with o.execute_sql(sql).open_reader() as reader:\n",
    "    for r in reader:\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aac37a8-b83a-4996-bc5b-141d8a2b6e22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
